{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "iJIW2XMfmJJc",
        "outputId": "0dfe047d-26ae-44c4-dc98-9e7505d95a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words list length:20000000\n",
            "Vocab size:4000\n",
            "Co-Matrix consumed mem:61.04MB\n",
            ">>>>> Process 1000000th word\n",
            ">>>>> Process 2000000th word\n",
            ">>>>> Process 3000000th word\n",
            ">>>>> Process 4000000th word\n",
            ">>>>> Process 5000000th word\n",
            ">>>>> Process 6000000th word\n",
            ">>>>> Process 7000000th word\n",
            ">>>>> Process 8000000th word\n",
            ">>>>> Process 9000000th word\n",
            ">>>>> Process 10000000th word\n",
            ">>>>> Process 11000000th word\n",
            ">>>>> Process 12000000th word\n",
            ">>>>> Process 13000000th word\n",
            ">>>>> Process 14000000th word\n",
            ">>>>> Process 15000000th word\n",
            ">>>>> Process 16000000th word\n",
            ">>>>> Process 17000000th word\n",
            ">>>>> Process 18000000th word\n",
            ">>>>> Process 19000000th word\n",
            ">>>>> Process 20000000th word\n",
            ">>>>> Save co-occurance matrix completed.\n",
            "Weight-Matrix consumed mem:61.04MB\n",
            ">>>>> Process 1000th weight\n",
            ">>>>> Process 2000th weight\n",
            ">>>>> Process 3000th weight\n",
            ">>>>> Process 4000th weight\n",
            ">>>>> Save weight matrix completed.\n",
            "Iterations: 551696 per one epoch, Total iterations: 5516960 \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c6661042c84b>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco_occur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#更新梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mloss_print_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mhas_sparse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             adagrad(\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36madagrad\u001b[0;34m(params, grads, state_sums, state_steps, has_sparse_grad, foreach, differentiable, lr, weight_decay, lr_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36m_single_tensor_adagrad\u001b[0;34m(params, grads, state_sums, state_steps, lr, weight_decay, lr_decay, eps, has_sparse_grad, maximize, differentiable)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mstate_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mstate_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import scipy\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "def getCorpus(size):\n",
        "    with open('corpus.txt', \"r\") as f:\n",
        "        text = f.read()\n",
        "        text = text.lower().split()\n",
        "        text = text[: min(len(text), size)]\n",
        "        vocab_dict = dict(Counter(text).most_common(MAX_VOCAB_SIZE - 1))\n",
        "        vocab_dict['<unk>'] = len(text) - sum(list(vocab_dict.values()))\n",
        "        idx_to_word = list(vocab_dict.keys())\n",
        "        word_to_idx = {word:ind for ind, word in enumerate(idx_to_word)}\n",
        "        word_counts = np.array(list(vocab_dict.values()), dtype=np.float32)\n",
        "        word_freqs = word_counts / sum(word_counts)\n",
        "        print(\"Words list length:{}\".format(len(text)))\n",
        "        print(\"Vocab size:{}\".format(len(idx_to_word)))\n",
        "    return text, idx_to_word, word_to_idx, word_counts, word_freqs\n",
        "\n",
        "def buildCooccuranceMatrix(text, word_to_idx):\n",
        "    vocab_size = len(word_to_idx)\n",
        "    maxlength = len(text)\n",
        "    text_ids = [word_to_idx.get(word, word_to_idx[\"<unk>\"]) for word in text]\n",
        "    cooccurance_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "    print(\"Co-Matrix consumed mem:%.2fMB\" % (sys.getsizeof(cooccurance_matrix)/(1024*1024)))\n",
        "    for i, center_word_id in enumerate(text_ids):\n",
        "        window_indices = list(range(i - WINDOW_SIZE, i)) + list(range(i + 1, i + WINDOW_SIZE + 1))\n",
        "        window_indices = [i % maxlength for i in window_indices]\n",
        "        window_word_ids = [text_ids[index] for index in window_indices]\n",
        "        for context_word_id in window_word_ids:\n",
        "            cooccurance_matrix[center_word_id][context_word_id] += 1\n",
        "        if (i+1) % 1000000 == 0:\n",
        "            print(\">>>>> Process %dth word\" % (i+1))\n",
        "    print(\">>>>> Save co-occurance matrix completed.\")\n",
        "    return cooccurance_matrix\n",
        "\n",
        "def buildWeightMatrix(co_matrix):\n",
        "    xmax = 100.0\n",
        "    weight_matrix = np.zeros_like(co_matrix, dtype=np.float32)\n",
        "    print(\"Weight-Matrix consumed mem:%.2fMB\" % (sys.getsizeof(weight_matrix) / (1024 * 1024)))\n",
        "    for i in range(co_matrix.shape[0]):\n",
        "        for j in range(co_matrix.shape[1]):\n",
        "            weight_matrix[i][j] = math.pow(co_matrix[i][j] / xmax, 0.75) if co_matrix[i][j] < xmax else 1\n",
        "        if (i+1) % 1000 == 0:\n",
        "            print(\">>>>> Process %dth weight\" % (i+1))\n",
        "    print(\">>>>> Save weight matrix completed.\")\n",
        "    return weight_matrix\n",
        "\n",
        "class WordEmbeddingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, co_matrix, weight_matrix):\n",
        "        self.co_matrix = co_matrix\n",
        "        self.weight_matrix = weight_matrix\n",
        "        self.train_set = []\n",
        "\n",
        "        for i in range(self.weight_matrix.shape[0]):\n",
        "            for j in range(self.weight_matrix.shape[1]):\n",
        "                if weight_matrix[i][j] != 0:\n",
        "                    self.train_set.append((i, j))\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        :return: the size of train_set\n",
        "        '''\n",
        "        return len(self.train_set)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        :return: one of the sample\n",
        "        '''\n",
        "        (i, j) = self.train_set[index]\n",
        "        return i, j, torch.tensor(self.co_matrix[i][j], dtype=torch.float), self.weight_matrix[i][j]\n",
        "\n",
        "class GloveModelForBGD(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.v = torch.nn.Embedding(vocab_size, embed_size)\n",
        "        self.w = torch.nn.Embedding(vocab_size, embed_size)\n",
        "        self.biasv = torch.nn.Embedding(vocab_size, 1)\n",
        "        self.biasw = torch.nn.Embedding(vocab_size, 1)\n",
        "\n",
        "        initrange = 0.5 / self.embed_size\n",
        "        self.v.weight.data.uniform_(-initrange, initrange)\n",
        "        self.w.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, i, j, co_occur, weight):\n",
        "        vi = self.v(i)\n",
        "        wj = self.w(j)\n",
        "        bi = self.biasv(i)\n",
        "        bj = self.biasw(j)\n",
        "\n",
        "        similarity = torch.mul(vi, wj)\n",
        "        similarity = torch.sum(similarity, dim=1)\n",
        "\n",
        "        loss = similarity + bi + bj - torch.log(co_occur)\n",
        "        loss = 0.5 * weight * loss * loss\n",
        "\n",
        "        return loss.sum().mean()\n",
        "\n",
        "    def gloveMatrix(self):\n",
        "        return self.v.weight.data.numpy() + self.w.weight.data.numpy()\n",
        "\n",
        "EMBEDDING_SIZE = 50\n",
        "MAX_VOCAB_SIZE = 4000\n",
        "WINDOW_SIZE = 5\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "LEARNING_RATE = 0.1\n",
        "TEXT_SIZE = 20000000\n",
        "WEIGHT_FILE = \"weight.txt\"\n",
        "\n",
        "text, idx_to_word, word_to_idx, word_counts, word_freqs = getCorpus(size=TEXT_SIZE)\n",
        "co_matrix = buildCooccuranceMatrix(text, word_to_idx)\n",
        "weight_matrix = buildWeightMatrix(co_matrix)\n",
        "dataset = WordEmbeddingDataset(co_matrix, weight_matrix)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "model = GloveModelForBGD(MAX_VOCAB_SIZE, EMBEDDING_SIZE)\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print_every = 10000\n",
        "save_every = 50000\n",
        "epochs = NUM_EPOCHS\n",
        "iters_per_epoch = int(dataset.__len__() / BATCH_SIZE)\n",
        "total_iterations = iters_per_epoch * epochs\n",
        "print(\"Iterations: %d per one epoch, Total iterations: %d \" % (iters_per_epoch, total_iterations))\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    loss_print_avg = 0\n",
        "    iteration = iters_per_epoch * epoch\n",
        "    for i, j, co_occur, weight in dataloader:\n",
        "        iteration += 1\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(i, j, co_occur, weight)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_print_avg += loss.item()\n",
        "torch.save(model.state_dict(), WEIGHT_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-rPP-RSmvr_d"
      },
      "outputs": [],
      "source": [
        "def find_nearest(word, embedding_weights):\n",
        "  index = word_to_idx[word]\n",
        "  embedding = embedding_weights[index]\n",
        "  cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) for e in embedding_weights])\n",
        "  return [idx_to_word[i] for i in cos_dis.argsort()[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOYTvkhFxGi7",
        "outputId": "6066a107-99fd-4e0b-ef15-37564fd38fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good ['good', 'very', 'because', 'bad', 'not', 'work', 'how', 'so', 'give', 'did']\n",
            "one ['one', 'only', 'has', 'all', 'two', 'also', 'which', 'for', 'this', 'that']\n",
            "green ['green', 'blue', 'white', 'yellow', 'dark', 'black', 'red', 'brown', 'orange', 'color']\n",
            "like ['like', 'some', 'other', 'often', 'such', 'very', 'make', 'these', 'have', 'because']\n",
            "america ['america', 'europe', 'america,', 'north', 'africa', 'central', 'western', 'america.', 'south', 'europe,']\n",
            "queen ['queen', 'elizabeth', 'king', 'daughter', 'prince', 'wife', 'anne', 'mary', 'maria', 'charles']\n",
            "better ['better', 'good', 'bad', 'way', 'find', 'get', 'because', 'without', 'so', 'much']\n",
            "work ['work', 'well', 'not', 'but', 'did', 'because', 'good', 'often', 'their', 'own']\n",
            "computer ['computer', 'software', 'uses', 'data', 'program', 'device', 'using', 'computers', 'use', 'programs']\n",
            "language ['language', 'language.', 'spoken', 'language,', 'languages', 'speak', 'word', 'programming', 'means', 'latin']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "for word in [\"good\", \"one\", \"green\", \"like\", \"america\", \"queen\", \"better\", \"work\", \"computer\", \"language\"]:\n",
        "  print(word, find_nearest(word, glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhL2N3K2xwYl",
        "outputId": "4950a88f-0a0b-46e5-fa94-cf0fa14ee5a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text ['text', 'sound', 'type', '\\\\na', 'referred', 'translation', 'commonly', 'sounds', 'code', '\"a']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"text\", find_nearest(\"text\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aexfSRNib0mt",
        "outputId": "fa1b8f3b-44b7-4857-c702-4c6d18f01894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "physics ['physics', 'chemistry', 'medicine', 'nobel', 'prize', 'quantum', 'physiology', 'mathematics', 'sciences', 'molecular']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"physics\", find_nearest(\"physics\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoLkEhnqb9wW",
        "outputId": "058dc978-2c23-490e-b445-6adc05d4bda5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "north ['north', 'south', 'central', 'east', 'west', 'western', 'southern', 'africa', 'america', 'australia.']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"north\", find_nearest(\"north\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYtNpljGcFxD",
        "outputId": "445de695-8624-45af-910d-678d8e911470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queen ['queen', 'elizabeth', 'king', 'daughter', 'prince', 'wife', 'anne', 'mary', 'maria', 'charles']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"queen\", find_nearest(\"queen\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JLv3OEpcMyx",
        "outputId": "6324ecc1-7999-4ac1-d3da-71f7009e6819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "car ['car', 'race', 'cars', 'motor', 'driver', 'company', 'produced', 'model', 'production', 'france.\\\\n\\\\nreferences\\\\ninsee\\\\n\\\\ncommunes']\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"car\", find_nearest(\"car\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9m7rIocNcZ1p"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(word_a, word_b, embedding_weights):\n",
        "  idx_a = word_to_idx[word_a]\n",
        "  idx_b = word_to_idx[word_b]\n",
        "  emb_a = embedding_weights[idx_a]\n",
        "  emb_b = embedding_weights[idx_b]\n",
        "  cos_dis = scipy.spatial.distance.cosine(emb_a, emb_b)\n",
        "  return cos_dis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H7YIb1bc9X6",
        "outputId": "9a079281-5b13-4e53-8be4-7416cb58d647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France vs. Spain 0.273925244808197\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"France vs. Spain\", cosine_similarity(\"france\", \"spain\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qNlSl1edoSn",
        "outputId": "ec226ba3-e7c4-4aca-a480-8c931257815b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tree vs. water 0.4943550229072571\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"tree vs. water\", cosine_similarity(\"tree\", \"water\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2RpUYWodvD3",
        "outputId": "b0459c60-a037-46cf-cc3a-e890960432d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "water vs. sky 0.7244596779346466\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"water vs. sky\", cosine_similarity(\"water\", \"sky\", glove_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hm9ik-Nd2E_",
        "outputId": "d9449307-4d40-40f5-fe16-50efccc962cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sky vs. bird 0.6768551766872406\n"
          ]
        }
      ],
      "source": [
        "glove_matrix = model.gloveMatrix()\n",
        "print(\"sky vs. bird\", cosine_similarity(\"sky\", \"bird\", glove_matrix))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
