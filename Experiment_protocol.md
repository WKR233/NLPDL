# 期末Project实验方案
<font size=5>2100017727 王柯然</font>

## 数据集构建方式

+ 需求1（对用户的输入进行摘要） 数据集构建：

    使用实际用户输入，比如用户评论、文章等。这个可以通过爬取具体网页（贴吧、豆瓣等论坛网页）或者使用公共数据集（[THUCNews](http://thuctc.thunlp.org/#%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86THUCNews)、[SogouCS](http://www.sogou.com/labs/resource/list_pingce.php)等）

    使用合成数据，例如随机将两个同类的文本进行合并，他们的摘要也进行合并，从而扩充数据集

+ 需求2（对用户的输入翻译为英文）数据集构建：

    采用公共数据集，且尽量贴近日常人们生活用语，例如数据集[AI-Challenger](https://challenger.ai/)等


## 模型训练方案

+ 先对GPT-2在摘要数据集上进行SFT训练直到它比较接近需求1，得到模型1

+ 然后使用in-context learning对GPT-2在翻译数据集1上进行训练，得到模型2

+ 再对模型1同样在翻译数据集1上使用in-context learning方法训练，得到模型3

+ 对比模型2和模型3在一个给定的翻译数据集2上的表现，比较他们的精度，并利用这一数据估算，较差的模型如果继续使用它的训练方法，需要多少数据集/时间才能做到和较好的模型具有相近的性能，进而估计出节约的成本。

## 拓展分析

+ 在现实生活中，很多时候一个ai（被期望）同时实现多种功能，这一结论能告诉我们是训练一个模型更有效率，还是在训练一个分类器之后训练多个模型，对用户的输入进行分类再喂入模型更有效率。

+ 同时这也能体现出一个模型对于微调到达的能力的记忆力，即经过一次其他的微调之后，初始的微调还能保持多少的表现能力，这有利于我们决定微调的先后顺序（如果二次微调更有效率的话）